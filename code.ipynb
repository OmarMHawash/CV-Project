{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import os\n",
    "# third party libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Config:\n",
    "    DEBUG_MODE = True\n",
    "    NUM_ROUND = 4\n",
    "    DEFAULT_COLOR = cv2.COLOR_BGR2RGB\n",
    "    STITCH_THESHOLD = 0.5\n",
    "    DETECT_CONF = 0.5\n",
    "    RESULTS_DIR = \"results/\" # append / at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Helper functions\"\"\"\n",
    "\n",
    "def depug_print(str):\n",
    "    if Config.DEBUG_MODE:\n",
    "        now = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f\"{now} - {str}\")\n",
    "    \n",
    "def normal_print(str):\n",
    "    print(f\"{str}\")\n",
    "\n",
    "def load_convert(path):\n",
    "    \"\"\"\n",
    "    Loads and converts an image to RGB\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(cv2.imread(path), Config.DEFAULT_COLOR)\n",
    "\n",
    "def ensure_results_directory():\n",
    "    \"\"\"Create the results directory if it doesn't exist.\"\"\"\n",
    "    os.makedirs(Config.RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "ensure_results_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Stitching #\n",
    "def stitch_match_2(left, right):\n",
    "    \"\"\"Function to stitch two images together\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    stitcher = cv2.Stitcher_create(cv2.Stitcher_PANORAMA)\n",
    "    stitcher.setPanoConfidenceThresh(Config.STITCH_THESHOLD)\n",
    "    status, res_I = stitcher.stitch([left, right])\n",
    "    end = time.time()\n",
    "\n",
    "    if status == cv2.Stitcher_OK:\n",
    "        depug_print(f\"stitch_match_2 took: {round(end-start, Config.NUM_ROUND)} seconds\")\n",
    "        return res_I\n",
    "    else:\n",
    "        if status == cv2.Stitcher_ERR_NEED_MORE_IMGS:\n",
    "            depug_print(\"Error: Need more images to stitch.\")\n",
    "        elif status == cv2.Stitcher_ERR_HOMOGRAPHY_EST_FAIL:\n",
    "            depug_print(\"Error: Homography estimation failed.\")\n",
    "        elif status == cv2.Stitcher_ERR_CAMERA_PARAMS_ADJUST_FAIL:\n",
    "            depug_print(\"Error: Camera parameters adjustment failed.\")\n",
    "        else:\n",
    "            depug_print(f\"Error during stitching: {status}\")\n",
    "        return None\n",
    "\n",
    "def stitch_3_imgs(images_folder):\n",
    "    \"\"\"\n",
    "    Requires 3 ordered RGB images\n",
    "    Returns stitched image if successful, otherwise None\n",
    "    \"\"\"\n",
    "    left = load_convert(f'{images_folder}/1.png')\n",
    "    center = load_convert(f'{images_folder}/2.png')\n",
    "    right = load_convert(f'{images_folder}/3.png')\n",
    "    \n",
    "    depug_print(\"Stitching left and center...\")\n",
    "    left_res = stitch_match_2(left, center)\n",
    "\n",
    "    if left_res is None:\n",
    "        depug_print(\"Stitching failed between left and center!\")\n",
    "        return\n",
    "\n",
    "    depug_print(\"Stitching center and right...\")\n",
    "    right_res = stitch_match_2(center, right)\n",
    "\n",
    "    if right_res is None:\n",
    "        depug_print(\"Stitching failed between center and right!\")\n",
    "        return\n",
    "\n",
    "    depug_print(\"Stitching final result between left-center and right...\")\n",
    "    final_stitch = stitch_match_2(left_res, right_res)\n",
    "\n",
    "    if final_stitch is None:\n",
    "        depug_print(\"Final stitching failed!\")\n",
    "    else:\n",
    "        depug_print(\"Stitching completed successfully!\")\n",
    "        cv2.imwrite(f\"{Config.RESULTS_DIR}/stitched.jpg\", final_stitch)\n",
    "\n",
    "    return final_stitch\n",
    "#############\n",
    "\n",
    "##################\n",
    "# Edge Detection #\n",
    "def apply_gaussian_blur(image, sigma):\n",
    "    \"\"\"Apply Gaussian Blur to the image with a given sigma.\"\"\"\n",
    "    return cv2.GaussianBlur(image, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "\n",
    "def difference_of_gaussians(image, sigma1, sigma2):\n",
    "    \"\"\"Calculate the Difference of Gaussians (DoG) for the image.\"\"\"\n",
    "    blur1 = apply_gaussian_blur(image, sigma1)\n",
    "    blur2 = apply_gaussian_blur(image, sigma2)\n",
    "    return blur1 - blur2\n",
    "\n",
    "def clean_dog_image(dog_image):\n",
    "    \"\"\"Apply morphological closing to the DoG image.\"\"\"\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    return cv2.morphologyEx(dog_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "def edge_detection_pipeline(image, sigma1, sigma2):\n",
    "    \"\"\"Complete edge detection pipeline using DoG.\"\"\"\n",
    "    \n",
    "    dog_image = difference_of_gaussians(image, sigma1, sigma2)\n",
    "    cleaned_dog = clean_dog_image(dog_image)\n",
    "\n",
    "    result_filename = f'{Config.RESULTS_DIR}edge_result.jpg'\n",
    "    cv2.imwrite(result_filename, cleaned_dog)\n",
    "    normal_print(f\"Result saved to {result_filename}\")\n",
    "    return cleaned_dog\n",
    "################\n",
    "\n",
    "#################\n",
    "# Predict people#\n",
    "def predict_people(image, model='yolov8x'):\n",
    "    \"\"\"Load the YOLO model, predict, and save the result image with bounding boxes.\"\"\"\n",
    "    model = YOLO(f'models/{model}.pt')\n",
    "    results = model.predict(source=image, conf=Config.DETECT_CONF)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        result.save(filename=f'{Config.RESULTS_DIR}detect_result.jpg')\n",
    "\n",
    "    normal_print(f\"Images saved to {Config.RESULTS_DIR}detect_result.jpg\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:56:45 - Stitching left and center...\n",
      "22:56:45 - stitch_match_2 took: 0.5233 seconds\n",
      "22:56:45 - Stitching center and right...\n",
      "22:56:46 - stitch_match_2 took: 0.4601 seconds\n",
      "22:56:46 - Stitching final result between left-center and right...\n",
      "22:56:47 - stitch_match_2 took: 0.8489 seconds\n",
      "22:56:47 - Stitching completed successfully!\n",
      "Result saved to results/edge_result.jpg\n",
      "\n",
      "0: 224x640 4 persons, 479.0ms\n",
      "Speed: 2.4ms preprocess, 479.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Images saved to results/detect_result.jpg\n"
     ]
    }
   ],
   "source": [
    "# Main program\n",
    "#* Note: all images saved locally in `/results` folder\n",
    "\n",
    "# must include in order, left to right 1, 2, 3\n",
    "stitch_folder = 'test'\n",
    "stitched = stitch_3_imgs(images_folder=stitch_folder)\n",
    "\n",
    "edge = edge_detection_pipeline(image=stitched, sigma1=1.0, sigma2=2.0)\n",
    "\n",
    "# uses by default the largest model\n",
    "predict = predict_people(image=stitched, model='yolov8x')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
